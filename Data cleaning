# Data Cleaning and Standardization: Layoffs Data

## Objective
The goal of this project is to clean, de-duplicate, and standardize a dataset containing layoffs information to prepare it for further analysis and ensure consistency and accuracy.

---

## Dataset
### Source:
Layoffs data (hypothetical or sourced from Kaggle/other platforms).

### Attributes:
- `company`: Name of the company.
- `location`: Location of the company.
- `industry`: Industry to which the company belongs.
- `total_laid_off`: Number of employees laid off.
- `percentage_laid_off`: Percentage of total employees laid off.
- `date`: Date of layoffs.
- `stage`: Business stage of the company.
- `country`: Country of the company.
- `funds_raised_millions`: Amount of funds raised by the company in millions.

---

## Project Steps

### 1. Creating a Staging Table
We created a staging table to work with the data without modifying the original dataset.
```sql
CREATE TABLE layoffs_stagging LIKE layoffs;
```

---

### 2. Identifying and Removing Duplicates
#### Step 1: Assigning Row Numbers to Potential Duplicates
Using `ROW_NUMBER` to identify duplicate rows.
```sql
WITH dup_lay AS (
    SELECT *, ROW_NUMBER() OVER (
        PARTITION BY company, location, industry, total_laid_off,
        percentage_laid_off, date, stage, country, funds_raised_millions
    ) AS rowno
    FROM layoffs_stagging
)
SELECT * FROM dup_lay WHERE rowno > 1;
```

#### Step 2: Creating a New Table to Remove Duplicates
We inserted unique records into a new table and removed duplicates.
```sql
CREATE TABLE layoffs_stagging2 AS
SELECT *, ROW_NUMBER() OVER (
    PARTITION BY company, location, industry, total_laid_off,
    percentage_laid_off, date, stage, country, funds_raised_millions
) AS rowno
FROM layoffs_stagging;

DELETE FROM layoffs_stagging2 WHERE rowno > 1;
ALTER TABLE layoffs_stagging2 DROP COLUMN rowno;
```

---

### 3. Standardizing Data
#### Trimming Whitespace
```sql
UPDATE layoffs_stagging2 SET company = TRIM(company);
```

#### Standardizing Industry Names
```sql
UPDATE layoffs_stagging2 SET industry = "crypto" WHERE industry LIKE "crypto%";
```

#### Cleaning Country Names
```sql
UPDATE layoffs_stagging2
SET country = TRIM(TRAILING '.' FROM country)
WHERE country LIKE "united states%";
```

#### Converting Date Format
```sql
UPDATE layoffs_stagging2
SET date = STR_TO_DATE(date, "%m/%d/%y");
ALTER TABLE layoffs_stagging2 MODIFY COLUMN date DATE;
```

---

### 4. Handling Null and Blank Values
#### Setting Null for Empty Industries
```sql
UPDATE layoffs_stagging2
SET industry = NULL
WHERE industry = "";
```

#### Filling Missing Industry Values Using Joins
```sql
UPDATE layoffs_stagging2 T1
JOIN layoffs_stagging2 T2
ON T1.company = T2.company
SET T1.industry = T2.industry
WHERE T1.industry IS NULL AND T2.industry IS NOT NULL;
```

#### Deleting Records with Missing Key Metrics
```sql
DELETE FROM layoffs_stagging2
WHERE total_laid_off IS NULL AND percentage_laid_off IS NULL;
```

---

### 5. Final Clean Dataset
The cleaned dataset was verified to ensure no duplicates and consistent formatting across all columns.

---

## Results
The project produced a cleaned and standardized dataset:
1. Free from duplicates.
2. Standardized across key attributes like `industry`, `country`, and `date`.
3. Ready for analysis or visualization.

---

## Conclusion
This project demonstrates key data cleaning techniques including:
- Using `ROW_NUMBER` for deduplication.
- Standardizing data with string manipulation and pattern matching.
- Handling null and inconsistent values effectively.

---

## Next Steps
1. **Visualization**: Create dashboards using Tableau or Power BI.
2. **Analysis**: Conduct exploratory data analysis to uncover trends.
3. **Documentation**: Share insights on LinkedIn or in a blog post.

---

### Files Included
1. **SQL Script**: [layoffs_data_cleaning.sql](#)  
2. **Cleaned Dataset**: [layoffs_cleaned.csv](#)

Feel free to clone this repository and explore the project!

